<p><img src="images/blog/Threads/MultithreadingInModernC++/timeline.jpg" alt="" width="700" height="305" style="display: block; margin-left: auto; margin-right: auto;" /></p>
<hr id="system-readmore" />
<p>Seit C++11 stellt sich C++ den Anforderungen der Multicore-Architekturen. Der 2011 veröffentlichte Standard definiert, wie sich ein C++ Programm beim mehreren Threads zu verhalten hat. Dabei setzen sich die C++11 Multithreading-Fähigkeiten aus zwei Komponenten zusammen. Das ist zum einen, das definierte Speichermodell, das ist zum anderen, die standardisierte Threading-Schnittstelle.</p>
<h2>Das definierte Speichermodell</h2>
<p>Das defininierte Speichermodell ist die notwendige Grundlage dafür, dass sich Multithreading Programme in C++ definiert verhalten. So beschäftigt sich das definierte Speichermodell mit den folgenden Fragen.</p>
<ol>
<li><span style="font-size: 12pt;">Was sind atomare Operationen?</span></li>
<li><span style="font-size: 12pt;">Welche Ordnung von Operationen ist gewährleistet?</span></li>
<li><span style="font-size: 12pt;">Wann sind Speichereffekte von Operationen sichtbar?</span></li>
</ol>
<p style="padding-left: 30px;">Zu 1. Atomare Operationen sind Operationen, die den ersten drei Buchstaben des berühmten <a href="https://de.wikipedia.org/wiki/ACID" rel="alternate">ACID</a>-Idioms aus der Datenbankentheorie folgen. Atomare Operationen sind atomar (A), gehen von einem konsistenten (C) Zustand in den nächsten und werden isoliert (I) ausgeführt. Das heißt insbesondere, kein anderer Thread kann einen Zwischenzustand einer atomaren Operation beobachten. Schön lässt sich die Konsistenz und Isoliertheit an einer Inkrementierung der Form <span style="font-family: courier new,courier;">atomVar</span>++ verdeutlichen. Falls<span style="font-family: courier new,courier;"> atomVar</span> eine atomare Variable ist, so kann <span style="font-family: courier new,courier;">atomVar</span> nur den alten oder den neuen um 1 erhöhten Wert besitzen. Die Konsistenz der Variable <span style="font-family: courier new,courier;">atomVar</span> besteht darin, dass sie von einem nur in den anderen Zustand wechseln, die Isoliertheit, dass ein anderer Thread keinen Zwischenwert beobachten kann.</p>
<p style="padding-left: 30px;">Zu 2. Sowohl der Compiler, der das Programm in Assembleranweisungen übersetzt, als auch der Prozessor, der die Assembleranweisungen ausführt, können die Operationen umordnen. Meist geschieht dies aus Performanzgründen. Zuletzt besitzen die verschiedenen Speicherebenen (Caches) auch noch die Möglichkeit, die Ergebnisse der Operationen verzögert zur Verfügung zu stellen.</p>
<p style="padding-left: 30px;">Zu 3. Da es durchaus sein kann, dass ein Thread eine Operation auf einer Speicherstelle später sieht als ein anderer Thread, gilt es hier, definierten Regeln zu folgen.</p>
<h2>Die standardisierte Threading-Schnittstelle</h2>
<p>Die standardisierte Threading-Schnittstelle in C++11 setzt sich aus den folgenden Komponenten zusammen.</p>
<ol>
<li><span style="font-size: 12pt;">Threads</span></li>
<li><span style="font-size: 12pt;">Tasks</span></li>
<li><span style="font-size: 12pt;">Thread-lokale Daten</span></li>
<li><span style="font-size: 12pt;">Bedingungsvariablen</span></li>
</ol>
<p style="padding-left: 30px;">Zu 1.Threads sind die elementaren Bausteine der Multithreading-Programmierung. Sie verrichten ihr Arbeitspaket autonom, werden mit Argumenten parametrisiert und interagieren mit anderen Threads über geteilte Variablen.</p>
<p style="padding-left: 30px;">Zu 2. Tasks sind ein relativ modernes Konzept. Tasks bestehen aus zwei Komponenten, die durch einen Kommunikationskanal verbunden sind. Dabei übernimmt ein Endpunkt des Kanals die Aufgabe, das Ergebnis der Berechnung zu Verfügung zu stellen, während&nbsp;der andere Endpunkt diese abholt. Der Produzent wird Promise genannt, der Konsument Future.</p>
<p style="padding-left: 30px;">Zu 3. Thread-lokale Daten sind Daten - wie der Namen leicht vermuten lässt -, die explizit einem Thread gehören.</p>
<p style="padding-left: 30px;">Zu 4. Bedingungsvariablen erlauben es Sender/Empfänger Arbeitsabläufe zu implementieren. Dabei wartet der Empfänger auf die Benachrichtigung des Senders, damit er seine Arbeit fortsetzen kann.</p>
<h2>Was bringt C++17 neues?</h2>
<p>Der nächste C++ Standard ist für 2017 geplant. C++17 wird vor allem viele Erweiterungen rund um die Multithreading-Fähigkeiten enthalten, den die bisherige Funktionalität ist sehr elementar. Diese Änderungen werden aller Voraussicht die drei folgenden interessanten Features enthalten:</p>
<ol>
<li><span style="font-size: 12pt;"><em>Latches</em> und <em>Barriers</em></span></li>
<li><span style="font-size: 12pt;"><em>Transactional Memory</em></span></li>
<li><span style="font-size: 12pt;">Automatisch parallelisierende oder auch vektorisierende Algorithmen der Standard Template Library (STL)</span></li>
</ol>
<p style="padding-left: 30px;">Zu 1. Latches und Barriers sind den bekannten <a href="https://de.wikipedia.org/wiki/Semaphor_%28Informatik%29" rel="alternate">Semaphoren</a> sehr ähnlich.</p>
<p style="padding-left: 30px;">Zu 2.<a href="https://de.wikipedia.org/wiki/Transaktionaler_Speicher" rel="alternate"> Transactional Memor</a>y ist vereinfachend gesprochen die ACID-Idee (wieder nur die ersten drei Buchstaben) auf Codeabschnitt angewandt. Das heißt, ein als <em>Transactional Memory</em> ausgezeichneter Codeabschnitt erlaubt es, auf Verdacht (optimistisch) ohne Synchronisation mit anderen Threads ausgeführt zu werden. Am Ende der Transaktion wird sein Ergebnis aber nur veröffentlicht, wenn die Ausgangsbedingungen noch zutreffen. Gelten diese nicht mehr, wird das Ergebnis der Transaktion verworfen und diese nochmals ausgeführt. Während das Locken des kritischen Bereichs mit Mutexen immer geschieht, wird bei der Transaktion der kritische Bereich nicht gelockt, dafür aber gegebenenfalls das Ergebnis verworfen. Ein kritischer Bereich ist ein Codeabschnitt, den nur maximal ein Threads zu einem Zeitpunkt betreten darf.</p>
<p style="padding-left: 30px;">Zu 3. Während parallelisierende Algorithmen die Operationen auf ihren Containern auf mehrere Threads verteilen, führen vektorisierende Algorithmen ihre Operationen auf mehreren Elementen ihres Containers in einem Schritt aus.</p>
<h2>Mein Plan</h2>
<p>In den nächsten Artikeln werde ich die Komponenten des C++-Speichermodells und der standardisierten Threading-Schnittstelle genauer beleuchten. Dabei wird mein Fokus nicht darauf liegen, jedes Detail genau aufzuarbeiten. Die Details sind im aktuellen C++-Standard ISO <em>International Standard ISO/IEC 14882:2014</em> oder auch auf der Internetressource <a href="http://en.cppreference.com/w/" rel="alternate">cppreference.com</a> sehr gut dokumentiert.</p>
<p><strong>Mein Fokus wird insbesondere in den nächsten Artikeln darauf liegen, typische Fehler im Umgang mit Multithreading-Programmen mit modernen C++ zu zeigen und Lösungen vorzustellen. Dazu werde ich&nbsp;soviel Theorie einfließen lassen, um das Problem und dessen Lösung zu verstehen. Los geht es mit der standardisierten Threading-Schnittstelle.</strong></p>
<h2>Wie geht's weiter?</h2>
<p>Im <a href="index.php/blog/threads">nächsten Artikel</a> beschäftige ich mich mit dem Erzeugen von Threads. <a href="index.php/blog/threads"><br /></a></p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>{tooltip} <img src="images/books/title_page_small.png" alt="title page small" width="166" height="212" />{end-texte}<img src="images/books/title_page_small.png" alt="title page small" style="margin: 3px;" /> Go to <a href="https://leanpub.com/cpplibrary"> </a><a href="https://leanpub.com/cpplibrary">Leanpub/cpplibrary</a> <a href="https://leanpub.com/cpplibrary"> </a><strong>"What every professional C++ programmer should know about the C++ standard library".</strong> <a href="https://leanpub.com/cpplibrary"></a>{end-tooltip} &nbsp; <strong><span class="h3">Hole dir dein E-Book. Unterstütze meinen Blog.</span></strong></p>
<p>&nbsp;</p>
