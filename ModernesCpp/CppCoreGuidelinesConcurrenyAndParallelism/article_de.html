<div class="vorspann">C++11 war der erste C++ Standard, der sich mit Concurrency beschäftigt. Der zentrale Baustein für Concurrency ist ein Thread. Dies ist der Grund, dass die meisten der Regeln sich mit Threads beschäftigen. Dies ändert sich dramatisch mit C++17.</div>
<div class="text">Mit C++17 wurde die Programmiersprache um die parallelen Algorithmen der Standard Template Library (STL) erweitert. Das bedeutet, dass die meisten der Algorithmen der STL sequenziell, parallel oder vektorisiert ausgeführt werden können. Für den neugierigen Leser: Ich habe bereits zwei Artikel zu der parallelen STL geschrieben. Der Artikel "<a href="https://www.grimm-jaud.de/index.php/blog/parallele-algorithmen-der-stl" title="Link auf https://www.grimm-jaud.de/index.php/blog/parallele-algorithmen-der-stl" alt="%7B%22href%22%3A%22https%3A%2F%2Fwww.grimm-jaud.de%2Findex.php%2Fblog%2Fparallele-algorithmen-der-stl%22%2C%22destination%22%3A%22https%3A%2F%2Fwww.grimm-jaud.de%2Findex.php%2Fblog%2Fparallele-algorithmen-der-stl%22%2C%22subject%22%3A%22%22%2C%22text%22%3A%22Parallele%20Algorithmen%20der%20Standard%20Template%20Library%22%2C%22anchor%22%3A%22%22%2C%22custom%22%3A%7B%7D%2C%22target%22%3A%22_blank%22%2C%22user_params%22%3A%22%22%2C%22ir_link%22%3A1%2C%22type%22%3A%22E%22%2C%22version%22%3A1%2C%22alias%22%3A%22%22%7D" class="">Parallele Algorithmen der Standard Template Library</a>" erklärt detailliert die Ausführungsstrategie, mit der sich die sequenzielle, parallele oder vektorisierte Ausführung der Algorithmen steuern lässt. C++17 wurde aber auch um neue Algorithmen erweitert, die für die parallele oder vektorisierte Ausführung konzipiert sind. Hier sind die Details: "<a class="" alt="%7B%22subject%22%3A%22%22%2C%22href%22%3A%22https%3A%2F%2Fwww.heise.de%2Fdeveloper%2Fartikel%2FNeue-Algorithmen-in-C-17-3704576.html%22%2C%22destination%22%3A%22https%3A%2F%2Fwww.heise.de%2Fdeveloper%2Fartikel%2FNeue-Algorithmen-in-C-17-3704576.html%22%2C%22custom%22%3A%7B%7D%2C%22anchor%22%3A%22%22%2C%22text%22%3A%22Neue%20Algorithmen%20in%20der%20C%2B%2B17%22%2C%22user_params%22%3A%22%22%2C%22target%22%3A%22%22%2C%22ir_link%22%3A1%2C%22type%22%3A%22E%22%2C%22alias%22%3A%22%22%2C%22version%22%3A1%7D" href="https://www.heise.de/developer/artikel/Neue-Algorithmen-in-C-17-3704576.html" title="Link auf https://www.heise.de/developer/artikel/Neue-Algorithmen-in-C-17-3704576.html">Neue Algorithmen in der C++17</a>".</div>
<div class="text"><img class="rteInlinetag" src="https://heise-cms.de/thumbs//TN_151875747_7caaea87e9.png" title="<ir_inline itemname=bilder_mvp_bild_var2:4 type=2>" style="max-height: 25px; max-width: 25px;"></div>
<div class="text">Die Concurrent-Geschichte in C++ geht weiter. Mit<b> C++20</b> können wir auf erweiterte Futures, Coroutinen, Transaktionen und noch mehr hoffen. Aus der Vogelperspektive betrachtet, sind die Concurrent-Features von C++11 und C++14 lediglich Implementierungsdetails, auf denen höhere Abstraktionen in C++17 und C++20 basieren. <a class="" href="https://www.grimm-jaud.de/index.php/blog/category/multithreading-c-17-und-c-20" title="Link auf https://www.grimm-jaud.de/index.php/blog/category/multithreading-c-17-und-c-20" alt="%7B%22custom%22%3A%7B%7D%2C%22anchor%22%3A%22%22%2C%22text%22%3A%22Hier%20ist%20die%20Serie%20zu%20all%20meinen%20Artikeln%20%C3%BCber%20die%20Concurrent%20Future%20in%20C%2B%2B20%22%2C%22subject%22%3A%22%22%2C%22destination%22%3A%22https%3A%2F%2Fwww.grimm-jaud.de%2Findex.php%2Fblog%2Fcategory%2Fmultithreading-c-17-und-c-20%22%2C%22href%22%3A%22https%3A%2F%2Fwww.grimm-jaud.de%2Findex.php%2Fblog%2Fcategory%2Fmultithreading-c-17-und-c-20%22%2C%22type%22%3A%22E%22%2C%22alias%22%3A%22%22%2C%22version%22%3A1%2C%22target%22%3A%22_blank%22%2C%22user_params%22%3A%22%22%2C%22ir_link%22%3A1%7D">Hier ist die Serie zu all meinen Artikeln über die Concurrent Future in C++20</a>.</div>
<div class="text">Wie ich bereits geschrieben habe: In den Regeln geht es hauptsächlich um Threads, da weder GCC noch Clang oder MSVC die parallelen Algorithmen vollständig implementiert haben. Es ist nicht sinnvoll, Best Practices zu Features aufzustellen, die nicht verfügbar (parallele STL) oder noch gar nicht standardisiert sind.</div>
<div class="text">Dies ist die erste Regel, dies es&nbsp; im Kopf zu behalten gilt. Die Regeln beschäftigen sich mit vorhandenen Multihreading-Features in C++11 und C++14. Die zweite Regel ist, dass Multithreading eine sehr anspruchsvolle Domäne ist. Das bedeutet, dass die Regeln Hilfen für die Anfänger und nicht die Experten in dieser Domäne anbieten. Die Regeln zum Speichermodell werden später folgen.</div>
<div class="text">Jetzt geht es endlich los mit der ersten Regel.<br></div>
<div class="text"><b><a class="" alt="%7B%22target%22%3A%22_blank%22%2C%22user_params%22%3A%22%22%2C%22ir_link%22%3A1%2C%22type%22%3A%22E%22%2C%22version%22%3A1%2C%22alias%22%3A%22%22%2C%22subject%22%3A%22%22%2C%22destination%22%3A%22http%3A%2F%2Fisocpp.github.io%2FCppCoreGuidelines%2FCppCoreGuidelines%23Rconc-multi%22%2C%22href%22%3A%22http%3A%2F%2Fisocpp.github.io%2FCppCoreGuidelines%2FCppCoreGuidelines%23Rconc-multi%22%2C%22custom%22%3A%7B%7D%2C%22text%22%3A%22CP.1%3A%20Assume%20that%20your%20code%20will%20run%20as%20part%20of%20a%20multi-threaded%20program%22%2C%22anchor%22%3A%22%22%7D" title="Link auf http://isocpp.github.io/CppCoreGuidelines/CppCoreGuidelines#Rconc-multi" href="http://isocpp.github.io/CppCoreGuidelines/CppCoreGuidelines#Rconc-multi">CP.1: Assume that your code will run as part of a multi-threaded program</a></b></div>
<div class="text">Ich war sehr erstaunt, als ich diese Regel zum ersten Mal las. Warum soll ich für den Spezialfall optimieren? Um es klar zu stellen: Diese Regel bezieht sich vor allem auf Bibliothek und nicht auf Applikationen. Die Erfahrung zeigt immer wieder, dass Bibliotheken häufig wiederverwendet werden. Das bedeutet natürlich, dass du für den allgemeinen Fall optimierst.<br></div>
<div class="text">Um die Regel auf den Punkt zu bringen, folgt hier ein kleines Codebeispiel.</div>
<div class="pre">double cached_computation(double x)<br>{<br>&nbsp;&nbsp;&nbsp; static double cached_x = 0.0;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; // (1)<br>&nbsp;&nbsp;&nbsp; static double cached_result = COMPUTATION_OF_ZERO;&nbsp; // (2)<br>&nbsp;&nbsp;&nbsp; double result;<br><br>&nbsp;&nbsp;&nbsp; if (cached_x == x)&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; // (1)<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; return cached_result;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; // (2)<br>&nbsp;&nbsp;&nbsp; result = computation(x);<br>&nbsp;&nbsp;&nbsp; cached_x = x;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; // (1)<br>&nbsp;&nbsp;&nbsp; cached_result = result;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; // (2)<br>&nbsp;&nbsp;&nbsp; return result;<br>}</div>
<div class="text">Die Funktion <i>cached_computation</i> erfüllt zuverlässig ihre Aufgabe, wenn sie in einem Single-threaded-Programm ausgeführt wird. Das gilt aber nicht in einer Umgebung, in der mehrere Threads verwendet werden. In diesem Fall ist das Problem, dass die statischen Variablen <i>cached_x </i>(1) und <i>cached_resul</i>t (2) gleichzeitig gelesen und verändert werden. Der C++11-Standard erweiterte statische Variablen mit Blockgültigkeit zwar um Multithreading-Semantik, dies gilt aber nur für ihre Initialisierung: Statische Variablen mit Blockgültigkeit werden thread-sicher initialisiert.&nbsp;</div>
<div class="text">Das ist praktisch, hilft aber nicht in dem konkreten Fall. Wird die Funktion <i>cached_computation </i>von mehreren Thread gleichzeitig aufgerufen, besitzt das Programm ein Data Race. Der Begriff Data Race ist sehr wichtig in Multithre-ding Programmen in C++. Daher will ich gerne genauer darauf eingehen.</div>
<div class="text">Ein Data Race ist eine Konstellation, in der zumindest zwei Threads auf eine geteilte Variable zugreifen. Zumindest ein Thread versucht sie dabei zu modifizieren. Der Rest ist schnell erklärt. Hat ein Programm ein Data Race, besitzt es undefiniertes Verhalten (undefined behaviour). Undefiniertes Verhalten bedeutet, dass jede weitere Analyse des Programms hinfällig ist und das Programm alle möglichen Ergebnisse produzieren kann. Ich meine wirklich alle. In meinen Seminaren sage ich gerne: Falls das Programm undefiniertes Verhalten besitzt, hat es Cache-Fire-Semantik. Selbst der Computer kann in Rauch aufgehen.<br></div>
<div class="text">Falls du die Definition eines Data Race genau studierst, wird dir auffallen, dass ein veränderlicher, geteilter Zustand notwendig für eine Data Race ist. Hier kommt einen kleine Tabelle um diese Beobachtung auf den Punkt zu bringen.</div>
<div class="text"><img class="rteInlinetag" src="https://heise-cms.de/thumbs//TN_151875742_da11d1f9c6.png" title="<ir_inline itemname=bilder_mvp_bild_var2:3 type=2>" style="max-height: 25px; max-width: 25px;"><br></div>
<div class="text">Was können wir tun, um das Data Race zu beseitigen? Die statischen Variablen variables <i>cached_x</i> (1) und <i>cached_resul</i>t (2) als konstant zu erklären, ist nicht zielführend. Das heißt natürlich im Umkehrschluss, beide Variablen sollten nicht geteilt werden. Hier sind ein paar Möglichkeiten, dies zu erreichen.<br></div>
<div class="text"><ol><li>Schütze beide statischen Variablen mit einem eigenen Lock.</li><li>Verwende ein Lock, um den ganzen kritischen Bereich zu schützen.</li><li>Schütze den Aufruf der Funktion function <i>cached_computation </i>durch ein Lock.</li><li>Mache beide statischen Variablen zu thread-lokalen Variablen. Thread-lokal sichert zu, dass jeder Thread seine eigene Kopie der Variablen <i>cached_x </i>und<i> cached_result </i>besitzt. Analog zu einer statischen Variable, die an die Lebenszeit des main-Thread gebunden ist, die die Lebenszeit einer thread-lokalen Variable an die Lebenszeit ihres Threads gebunden.&nbsp;<br></li></ol></div>
<div class="text">Hier sind die Variationen 1, 2, 3 und 4.</div>
<div class="pre">std::mutex m_x;<br>std::mutex m_result;<br>double cached_computation(double x){&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; // (1)<br>&nbsp;&nbsp;&nbsp; static double cached_x = 0.0;<br>&nbsp;&nbsp;&nbsp; static double cached_result = COMPUTATION_OF_ZERO;<br>&nbsp;&nbsp;&nbsp;<br>&nbsp;&nbsp;&nbsp; double result;<br>&nbsp;&nbsp;&nbsp; {<br>&nbsp;&nbsp;&nbsp; std::scoped_lock(m_x, m_result);<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; if (cached_x == x) return cached_result;<br>&nbsp;&nbsp;&nbsp; }<br>&nbsp;&nbsp;&nbsp; result = computation(x);<br>&nbsp;&nbsp;&nbsp; {<br>&nbsp;&nbsp;&nbsp; std::lock_guard&lt;std::mutex&gt; lck(m_x);<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; cached_x = x;<br>&nbsp;&nbsp;&nbsp; }<br>&nbsp;&nbsp;&nbsp; {<br>&nbsp;&nbsp;&nbsp; std::lock_guard&lt;std::mutex&gt; lck(m_result);&nbsp;<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; cached_result = result;<br>&nbsp;&nbsp;&nbsp; }<br>&nbsp;&nbsp;&nbsp; return result;<br>}<br><br>std::mutex m;<br>double cached_computation(double x){&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; // (2)<br>&nbsp;&nbsp;&nbsp; static double cached_x = 0.0;<br>&nbsp;&nbsp;&nbsp; static double cached_result = COMPUTATION_OF_ZERO;<br>&nbsp;&nbsp;&nbsp; double result;<br>&nbsp;&nbsp;&nbsp; {<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; std::lock_guard&lt;std::mutex&gt; lck(m);<br>&nbsp;&nbsp;&nbsp; if (cached_x == x) return cached_result;<br>&nbsp;&nbsp;&nbsp; result = computation(x);<br>&nbsp;&nbsp;&nbsp; cached_x = x;<br>&nbsp;&nbsp;&nbsp; cached_result = result;<br>&nbsp;&nbsp;&nbsp; }<br>&nbsp;&nbsp;&nbsp; return result;<br>}<br><br>std::mutex cachedComputationMutex;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; // (3)<br>{<br>&nbsp;&nbsp;&nbsp; std::lock_guard&lt;std::mutex&gt; lck(cachedComputationMutex);<br>&nbsp;&nbsp;&nbsp; auto cached = cached_computation(3.33);<br>}<br><br><br>double cached_computation(double x){&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; // (4)<br>&nbsp;&nbsp;&nbsp; thread_local double cached_x = 0.0;<br>&nbsp;&nbsp;&nbsp; thread_local double cached_result = COMPUTATION_OF_ZERO;<br>&nbsp;&nbsp;&nbsp; double result;<br><br>&nbsp;&nbsp;&nbsp; if (cached_x == x) return cached_result;<br>&nbsp;&nbsp;&nbsp; result = computation(x);<br>&nbsp;&nbsp;&nbsp; cached_x = x;<br>&nbsp;&nbsp;&nbsp; cached_result = result;<br>&nbsp;&nbsp;&nbsp; return result;<br>}</div>
<div class="text">Zuerst einmal gilt, dass statische Variablen thread-sicher initialisiert werden. Daher muss deren Initialisierung in dem Programmschnipsel nicht geschützt werden.<br></div>
<div class="text"><ol><li>Diese Version ist ein wenig trickreich, denn ich muss insbesondere beide Locks in einem atomaren Schritt anfordern. C++17 bietet dafür den <i>std::scoped_lock </i>an. Dieser kann eine beliebige Anzahl von Locks in einem atomaren Schritt locken. In C++11 bietet sich eine <i>std::unique_lock</i> in Kombination mit der Funktion <i>std::lock an</i>. Meine Artikel <a title="Link auf https://www.grimm-jaud.de/index.php/blog/verklemmungen-loesen" href="https://www.grimm-jaud.de/index.php/blog/verklemmungen-loesen" alt="%7B%22text%22%3A%22Locks%20statt%20Mutexen%22%2C%22anchor%22%3A%22%22%2C%22custom%22%3A%7B%7D%2C%22destination%22%3A%22https%3A%2F%2Fwww.grimm-jaud.de%2Findex.php%2Fblog%2Fverklemmungen-loesen%22%2C%22href%22%3A%22https%3A%2F%2Fwww.grimm-jaud.de%2Findex.php%2Fblog%2Fverklemmungen-loesen%22%2C%22subject%22%3A%22%22%2C%22type%22%3A%22E%22%2C%22alias%22%3A%22%22%2C%22version%22%3A1%2C%22user_params%22%3A%22%22%2C%22target%22%3A%22_blank%22%2C%22ir_link%22%3A1%7D" class="">Locks statt Mutexen</a> bietet weitere Details zu Locks in C++11 und C++14.</li><li>Die Version 2 verwendet eine gröbere Strategie. Normalerweise solltest du kein grob-granulares Locken anwenden, aber ich denke, in diesem Anwendungsfall ist es OK.&nbsp;</li><li>Dieser Ansatz ist mit Abstand der grob-granularste, denn die ganze Funktion wird gelockt. Klar, der Nachteil dieser Option ist es, dass der Anwender der Funktion für die Synchronisation des Funktionsaufrufs verantwortlich ist. Das ist, allgemein gesprochen, eine sehr schlechte Idee.</li><li>Erkläre einfach deine statischen Variablen als thread-lokal und schon ist das Problem gelöst.<br></li></ol></div>
<div class="text">Am Ende hängt die Frage, welche Option gewählt wird, von deren Performanz und den Anwendern ab. Daher solltest du jede Version testen, ihre Performanz messen und dir Gedanken zu den Programmierern machen, die die Funktion anwenden und weiterpflegen.</div>
<div class="ztitel">Wie geht's weiter?</div>
<div class="text">Dieser Artikel war lediglich der Startpunkt zu einer längeren Reise durch die Regeln zu Concurrency in C++. Im nächsten Artikel werde ich über Threads und geteilten Zustand schreiben.&nbsp;</div>
<div class="ztitel">Weitere Informationen:</div>
<div class="text">Für meine drei offenen Seminare im zweiten Halbjahr 2018 sind noch Plätze frei. Die Schulungen finden im Großraum Stuttgart statt.</div>
<div class="text"><ul><li>Embedded-Programmierung mit modernem C++: 10.07 - 12.07 (Termingarantie)<br></li><li>C++11 und C++14: 11.09 - 13.09</li><li>Multithreading mit modernem C++: 13.11 - 14.11</li></ul></div>
<div class="text">Unter <a class="" alt="%7B%22destination%22%3A%22https%3A%2F%2Fwww.modernescpp.de%2Findex.php%2Fc%22%2C%22href%22%3A%22https%3A%2F%2Fwww.modernescpp.de%2Findex.php%2Fc%22%2C%22subject%22%3A%22%22%2C%22text%22%3A%22www.ModernesCpp.de%22%2C%22anchor%22%3A%22%22%2C%22custom%22%3A%7B%7D%2C%22target%22%3A%22_blank%22%2C%22user_params%22%3A%22%22%2C%22ir_link%22%3A1%2C%22type%22%3A%22E%22%2C%22version%22%3A1%2C%22alias%22%3A%22%22%7D" href="https://www.modernescpp.de/index.php/c" title="Link auf https://www.modernescpp.de/index.php/c">www.ModernesCpp.de</a> sind die Details zu den drei Schulungen.</div>
<div class="text">Ich freue mich immer darauf, mein Wissen vermitteln zu dürfen.</div>
