<div class="vorspann">Blockierend, nichtblockierend, "lock-free" und "wait-free". Jeder dieser Begriffe beschreibt eine Charakteristik eines Algorithmus, wenn er in einer nebenläufigen Umgebung ausgeführt wird. Macht man sich daher Gedanken zum Laufzeitverhalten eines Programms, bedeutet es oft, ihn ins richtige Körbchen zu legen. Daher geht es heute um das Einsortieren.<br></div><div class="text">Ein&nbsp; Algorithmus fällt in eine von zwei Kategorien: blockierend oder nicht-. </div><div class="text"><img class="rteInlinetag" src="https://heise-cms.de/thumbs//TN_135288005_e625a90e8d.png" title="<ir_inline itemname=bilder_mvp_bild_var2:2 type=2>" style="max-height: 25px; max-width: 25px;">Los geht es mit den blockierenden Algorithmen.<br></div><div class="ztitel">Blockierend</div><div class="text">Intuitiv wissen wir natürlich, was blockierend für einen Algorithmus bedeutet. Aber bei Gleichzeitigkeit geht es nicht um Intuition, hier geht es um präzise Begriffe. Der einfachste Weg, "blockierend" für einen Algorithmus&nbsp; zu definieren, ist es, sich auf nichtblockierend zurückzuziehen. Der Begriff wird sehr schön in dem Buch "Java Concurreny in Practice" definiert. <br></div><div class="text"><ul><li> "Non-blocking: An algorithm is called non-blocking if failure or suspension of any thread cannot cause failure or suspension of another thread." (Ein Algorithmus heißt nichtblockierend, wenn ein Fehler oder die Sperre eines Threads nicht zu einem Fehler oder der Sperre eines anderen Threads führt.)</li></ul></div><div class="text">Die Definition enthält nicht den Ausdruck "Lock". Das ist richtig, denn nichtblockierend ist ein allgemeinerer Ansatz. </div><div class="text">Ein Programm zu "blockierend" ist ziemlich einfach. Das typische Kochrezept besteht darin, mehr als einen Mutex zu verwenden und sie in verschiedene Reihenfolgen zu locken. Glückliches Timing, und schon gibt es ein Deadlock. Aber es gibt viel mehr Rezepte, um einen blockierenden Algorithmus zu erzeugen. Jedes Mal, wenn man auf eine Ressource warten musst, lauert eine Blockade.</div><div class="text">Hier sind ein paar Beispiele für synchronisierte Zugriffe auf eine Ressource:</div><div class="text"><ul><li> eine Bedingungsvariable mit <i>wait</i>.</li><li> ein Future mit <i>get </i> oder <i>wait</i>.&nbsp; &nbsp;&nbsp; <br></li></ul></div><div>Selbst der <i>join</i>-Aufruf auf einem Thread kann mit ein wenig Innovation dazu verwendet werden, einen Thread für immer zu blockieren.</div><div class="pre">// deadlockWait.cpp<br><br>#include &lt;iostream&gt;<br>#include &lt;mutex&gt;<br>#include &lt;string&gt;<br>#include &lt;thread&gt;<br><br>std::mutex coutMutex;<br><br>int main(){<br><br>&nbsp; std::thread t([]{<br>&nbsp;&nbsp;&nbsp; std::cout &lt;&lt; "Still waiting ..." &lt;&lt; std::endl;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; // 2<br>&nbsp;&nbsp;&nbsp; std::lock_guard&lt;std::mutex&gt; lockGuard(coutMutex);&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; // 3<br>&nbsp;&nbsp;&nbsp; std::cout &lt;&lt; "child: " &lt;&lt; std::this_thread::get_id() &lt;&lt; std::endl;}<br>&nbsp; );<br><br>&nbsp; {<br><br>&nbsp;&nbsp;&nbsp; std::lock_guard&lt;std::mutex&gt; lockGuard(coutMutex);&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; // 1<br>&nbsp;&nbsp;&nbsp; std::cout &lt;&lt; "creator: " &lt;&lt; std::this_thread::get_id() &lt;&lt; std::endl;<br><br>&nbsp;&nbsp;&nbsp; t.join();&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; // 5<br><br>&nbsp; }&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; // 4<br><br>}</div><div class="text">Die Programmausführung bleibt sofort stehen.</div><div class="text"><img class="rteInlinetag" src="https://heise-cms.de/thumbs//TN_135288009_00f63fcc5c.png" title="<ir_inline itemname=bilder_mvp_bild_var2:3 type=2>" style="max-height: 25px; max-width: 25px;"></div><div class="text">Was passiert hier? Der Erzeuger-Thread lockt (1) den Mutex. Nun führt das Kind (2) aus. Damit das Kind den Mutex (3) erhält, muss der Erzeuger-Thread diesen erst wieder freigeben. Aber der Erzeuger-Thread gibt den Mutex erst dann wieder frei, wenn der <i>lockGuard</i> (1) seinen Gültigkeitsbereich (4) verlässt. Das passiert aber nie, denn der Kinder-Thread muss dazu erst den Mutex <i>coutMutex</i> locken. <br> </div><div class="text">Auf die blockierenden folgen nun die nichtblockierenden Algorithmen. </div><div class="ztitel">Nichtblockierend </div><div class="text"><img class="rteInlinetag" src="https://heise-cms.de/thumbs//TN_135288015_60ae969189.png" title="<ir_inline itemname=bilder_mvp_bild_var2:4 type=2>" style="max-height: 25px; max-width: 25px;"></div><div class="text">Die Hauptkategorien für nichtblockierende Algorithmen sind "lock-free" und "wait-free". Jeder Wait-free-Algorithmus ist "lock-free", und jeder Lock-free-Algorithmus ist nichtblockierend. Nichtblockierend und "lock-free" sind aber verschiedene Konzepte. Es gibt eine zusätzliche Zusicherung, die "obstruction-free" genannt wird. Diese werde ich aber in diesem Artikel ignorieren, da sie nicht besonders relevant ist. Nichtblockierende Algorithmen werde typischerweise mit CAS-Anweisungen umgesetzt. </div><div class="text">CAS steht für "compare and swap". CAS heißt in C++ <i>compare_exchange_strong</i> oder <i>compare_exchange_weak</i>. Ich werde in diesem Artikel die Strong-Version verwenden. Falls mehr Information benötigt werden, finden sie sich in meinen Artikel "<a title="Link auf http://www.grimm-jaud.de/index.php/blog/der-atomare-wahrheitswert" alt="%7B%22href%22%3A%22http%3A%2F%2Fwww.grimm-jaud.de%2Findex.php%2Fblog%2Fder-atomare-wahrheitswert%22%2C%22destination%22%3A%22http%3A%2F%2Fwww.grimm-jaud.de%2Findex.php%2Fblog%2Fder-atomare-wahrheitswert%22%2C%22anchor%22%3A%22%22%2C%22alias%22%3A%22%22%2C%22user_params%22%3A%22%22%2C%22subject%22%3A%22%22%2C%22custom%22%3A%7B%7D%2C%22ir_link%22%3A1%2C%22text%22%3A%22Der%20atomare%20Wahrheitswert%22%2C%22type%22%3A%22E%22%2C%22version%22%3A1%2C%22target%22%3A%22_blank%22%7D" href="http://www.grimm-jaud.de/index.php/blog/der-atomare-wahrheitswert">Der atomare Wahrheitswert</a>". Die zentrale Idee beider Algorithmen ist es, dass der Aufruf <i>atomicValue.compare_exchange_strong(expected, desired)</i> die folgende Strategie in atomare Weise umsetzt.<br><ul><li>Falls der Vergleich von <i>atomicValue</i> mit <i>expected</i> <i>true</i> ergibt, wird in derselben atomaren Operation <i>atomicValue</i> auf <i> desired</i> gesetzt. </li><li>Falls der Vergleich <i>false</i> zurückgibt, wird <i>expected</i> auf <i>atomicValue</i> gesetzt. </li></ul></div><div class="text">Jetzt möchte ich einen genaueren Blick auf "lock-free" und "wait-free" werfen. Beginnen werde ich mit den Definitionen von "lock-free" und "wait-free". Beide Definitionen sind sehr ähnlich. Daher ergibt es Sinn, diese gegenüberzustellen. </div><div class="text"><ul><li><b>Lock-free</b>: Ein nichtblockierender Algorithmus ist "lock-free", falls ein systemweiter Fortschritt zugesichert ist.&nbsp; </li></ul><ul><li><b>Wait-free</b>: Ein nichtblockierender Algorithmus ist "wait-free", falls ein Fortschritt für jeden Thread zugesichert ist. </li></ul></div><div class="ztitel">Lock-free</div><div class="pre">// fetch_mult.cpp<br><br>#include &lt;atomic&gt;<br>#include &lt;iostream&gt;<br><br>template &lt;typename T&gt;<br>T fetch_mult(std::atomic&lt;T&gt;&amp; shared, T mult){&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; // 1<br>&nbsp; T oldValue = shared.load();&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; // 2<br>&nbsp; while (!shared.compare_exchange_strong(oldValue, oldValue * mult));&nbsp; // 3<br>&nbsp; return oldValue;<br>}<br><br>int main(){<br>&nbsp; std::atomic&lt;int&gt; myInt{5};<br>&nbsp; std::cout &lt;&lt; myInt &lt;&lt; std::endl;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <br>&nbsp; fetch_mult(myInt,5);<br>&nbsp; std::cout &lt;&lt; myInt &lt;&lt; std::endl;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <br>}</div><div class="text">Der Algorithmus <i>fetch_mult</i> (1) multipliziert eine <i> std::atomic shared </i> mit <i>mult</i>. Die entscheidende Beobachtung ist es, dass es ein kleines Zeitfenster zwischen dem Lesen des alten Werts <i> oldValue = shared Load</i> (2) und dem Vergleich mit dem neuen Wert (3) gibt. Daher kann immer ein anderer Thread zu genau diesem Zeitpunkt den alten Wert ändern. Wer sich diese verschränkte Ausführung von Threads vergegenwärtigt, dem ist unmittelbar klar, dass der Algorithmus keinen Fortschritt für jeden Thread garantieren kann. Daher ist der Algorithmus "lock-free", aber nicht "wait-free".</div><div class="text">Hier ist die Ausgabe des Programms.</div><div class="text"><img class="rteInlinetag" src="https://heise-cms.de/thumbs//TN_135288019_b77facd258.png" title="<ir_inline itemname=bilder_mvp_bild_var2:5 type=2>" style="max-height: 25px; max-width: 25px;"></div><div class="text">Während ein Lock-free-Algorithmus systemweiten Fortschritt garantiert, garantiert ein Wait-free-Algorithmus Fortschritt für jeden Thread. </div><div class="ztitel">Wait-free</div><div class="text">Wenn man sich den Lock-free-Algorithmus im letzten Beispiel genauer anschaut, wird auffallen, dass ein <i>compare_exchange_strong</i>-Aufruf Synchronisation anwendet. Zuerst wird der alte Wert ausgelesen und dann wird der neue Wert gesetzt, falls die Anfangsbedingung noch zutrifft. Falls das gilt, wird der neue Wert veröffentlicht. Wenn nicht, werden die Schritte&nbsp;wiederholt, falls man ihn in einer<i> while-</i>Schleife verwendet. &nbsp; Daher verhält sich<i> compare_exchange_strong</i> wie eine atomare Transaktion.</div><div class="text">Die entscheidenden Zeilen des nächsten Programms kommen ganz ohne Synchronisation aus. </div><div class="pre">// relaxed.cpp<br><br>#include &lt;vector&gt;<br>#include &lt;iostream&gt;<br>#include &lt;thread&gt;<br>#include &lt;atomic&gt;<br>&nbsp;<br>std::atomic&lt;int&gt; cnt = {0};<br>&nbsp;<br>void add(){&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; // 1<br>&nbsp;&nbsp;&nbsp; for (int n = 0; n &lt; 1000; ++n) {<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; cnt.fetch_add(1, std::memory_order_relaxed);&nbsp; // 2<br>&nbsp;&nbsp;&nbsp; }<br>}<br>&nbsp;<br>int main(){<br>&nbsp;&nbsp;&nbsp; std::vector&lt;std::thread&gt; v;<br>&nbsp;&nbsp;&nbsp; for (int n = 0; n &lt; 10; ++n) {<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; v.emplace_back(add);<br>&nbsp;&nbsp;&nbsp; }<br>&nbsp;&nbsp;&nbsp; for (auto&amp; t : v) {<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; t.join();<br>&nbsp;&nbsp;&nbsp; }<br>&nbsp;&nbsp;&nbsp; std::cout &lt;&lt; "Final counter value is " &lt;&lt; cnt &lt;&lt; '\n';<br>}</div><div class="text">Die Funktion <i>add</i> (1) ist einen scharfen Blick wert. Der Ausdruck (2) kommt ohne Synchronisation aus. Der atomare Wert<i> cnt </i>wird lediglich um 1 inkrementiert. Und hier kommt die Ausgabe des Programms. Das Ergebnis ist immer 1000, da 10 Threads 1000 Mal 1 hinzuaddieren.&nbsp;</div><div class="text"><img class="rteInlinetag" src="https://heise-cms.de/thumbs//TN_135288025_81b04b02d0.png" title="<ir_inline itemname=bilder_mvp_bild_var2:6 type=2>" style="max-height: 25px; max-width: 25px;">&nbsp;</div><div class="text">Der Einfachheit halber, habe ich ein paar weitere Zusicherungen wie "starvation-free" als Untermenge von blockierenden Algorithmen oder "wait-free bounded" als Untermenge von Wait-free-Algorithmen in diesem Artikel ignoriert. Die Details dazu lassen sich schön auf dem Blog "<a title="Link auf http://concurrencyfreaks.blogspot.de/2013/05/lock-free-and-wait-free-definition-and.html" href="http://concurrencyfreaks.blogspot.de/2013/05/lock-free-and-wait-free-definition-and.html" alt="%7B%22text%22%3A%22Concurreny%20Freaks%22%2C%22custom%22%3A%7B%7D%2C%22ir_link%22%3A1%2C%22subject%22%3A%22%22%2C%22user_params%22%3A%22%22%2C%22alias%22%3A%22%22%2C%22anchor%22%3A%22%22%2C%22destination%22%3A%22http%3A%2F%2Fconcurrencyfreaks.blogspot.de%2F2013%2F05%2Flock-free-and-wait-free-definition-and.html%22%2C%22href%22%3A%22http%3A%2F%2Fconcurrencyfreaks.blogspot.de%2F2013%2F05%2Flock-free-and-wait-free-definition-and.html%22%2C%22target%22%3A%22_blank%22%2C%22version%22%3A1%2C%22type%22%3A%22E%22%7D">Concurreny Freaks</a>" nachlesen.<br></div><div class="ztitel">Wie geht's weiter?</div><div class="text">Im nächsten Artikel schreibe ich über eine Kuriosität. Sieheißt ABA und stellr eine Art "false positive" für CAS-Anweisungen dar. Das bedeutet, obwohl es scheint, dass der alte Wert eines CAS-Befehls sich nicht geändert hat, ist er in der Zwischenzeit doch verändert worden.&nbsp; </div>